# Ultralytics YOLO ðŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 4  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]

  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, ContextGuidedBlock_Down, []]  # 1-P2/4
  - [-1, 3, C2f_ContextGuided, [128, True]]
  - [-1, 1, ContextGuidedBlock_Down, []]  # 3-P3/8
  - [-1, 6, C2f_ContextGuided, [256, True]]
  - [-1, 1, ContextGuidedBlock_Down, []]  # 5-P4/16
  - [-1, 6, C2f_ContextGuided, [512, True]]
  - [-1, 1, ContextGuidedBlock_Down, []]  # 7-P5/32
  - [-1, 3, C2f_ContextGuided, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9

# YOLOv8.0n head
head:
  - [-1, 1, Conv, [512, 1, 1]] # 10
  - [4, 1, Conv, [512, 1, 1]] # 11
  - [[-1, 6, -2], 1, Zoom_cat, []]  # 12 cat backbone P4
  - [-1, 3, C2f, [512]]  # 13

  - [-1, 1, Conv, [256, 1, 1]] # 14
  - [2, 1, Conv, [256, 1, 1]] # 15
  - [[-1, 4, -2], 1, Zoom_cat, []]  # 16  cat backbone P3
  - [-1, 3, C2f, [256]]  # 17 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]] # 18
  - [[-1, 14], 1, Concat, [1]]  # 19 cat head P4
  - [-1, 3, C2f, [512]]  # 20 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]] # 21
  - [[-1, 10], 1, Concat, [1]]  # 22 cat head P5
  - [-1, 3, C2f, [512]]  # 23 (P5/32-large)

  - [[4, 6, 8], 1, ScalSeq, [256]] # 24 args[inchane]
  - [[17, -1], 1, asf_attention_model, []] # 25

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']] # 26
  - [[-1, 2], 1, Concat, []]  # 27  cat backbone P2
  - [-1, 3, C2f, [128]]  # 28 (P2/4-small)

  - [[2, 25, 20], 1, ScalSeq, [128]] # 29 args[inchane]
  - [[28, -1], 1, asf_attention_model, []] # 30

  - [[30, 25, 20, 23], 1, Detect, [nc]]  # RTDETRDecoder(P3, P4, P5)